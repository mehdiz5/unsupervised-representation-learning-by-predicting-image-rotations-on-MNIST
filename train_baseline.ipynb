{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 16:17:32.962586: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-29 16:17:32.972961: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732893452.986145 2719517 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732893452.989918 2719517 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-29 16:17:33.004132: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from models import ConvNet\n",
    "from helper_functions import train_convnet, evaluate_classifier, rotation_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BLOCKS=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root='./data', \n",
    "                         train=True, \n",
    "                         download=True, \n",
    "                         transform=transforms.ToTensor())\n",
    "\n",
    "targets = np.array(dataset.targets)\n",
    "\n",
    "# Select 10 indices for each class\n",
    "indices = []\n",
    "for digit in range(10):\n",
    "    digit_indices = np.where(targets == digit)[0][:10]  # Take first 10 samples for each digit\n",
    "    indices.extend(digit_indices)\n",
    "\n",
    "\n",
    "supervised_dataset = Subset(dataset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST(root='./data', \n",
    "                              train=False, \n",
    "                              download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_train_loader = DataLoader(supervised_dataset, \n",
    "                                     batch_size=8,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=4,\n",
    "                                     persistent_workers=True)\n",
    "supervised_val_loader = DataLoader(test_dataset, \n",
    "                                   batch_size=128, \n",
    "                                   shuffle=False,\n",
    "                                   num_workers=4,\n",
    "                                   persistent_workers=True)\n",
    "\n",
    "baseline_model=ConvNet(num_classes=10).cuda()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer=torch.optim.Adam(baseline_model.parameters(),lr=0.0001,weight_decay=0.001)\n",
    "learning_rate_scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=500,gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_model=ConvNet(num_classes=10,num_blocks=NUM_BLOCKS).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Training]: 100%|██████████| 13/13 [00:00<00:00, 30.75it/s, loss=1.1419]\n",
      "Epoch 1/10 [Validation]: 100%|██████████| 1250/1250 [00:01<00:00, 652.95it/s]\n",
      "/home/rami/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Train Loss: 1.9692, Train Accuracy: 35.00%, Validation Loss: 2.4703, Validation Accuracy: 11.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Training]: 100%|██████████| 13/13 [00:00<00:00, 178.89it/s, loss=0.7990]\n",
      "Epoch 2/10 [Validation]: 100%|██████████| 1250/1250 [00:01<00:00, 687.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] - Train Loss: 0.8115, Train Accuracy: 86.00%, Validation Loss: 3.0947, Validation Accuracy: 11.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Training]: 100%|██████████| 13/13 [00:00<00:00, 221.33it/s, loss=0.3390]\n",
      "Epoch 3/10 [Validation]: 100%|██████████| 1250/1250 [00:01<00:00, 690.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] - Train Loss: 0.2658, Train Accuracy: 97.00%, Validation Loss: 1.4041, Validation Accuracy: 50.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Training]: 100%|██████████| 13/13 [00:00<00:00, 224.53it/s, loss=0.0727]\n",
      "Epoch 4/10 [Validation]: 100%|██████████| 1250/1250 [00:01<00:00, 663.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] - Train Loss: 0.0839, Train Accuracy: 99.00%, Validation Loss: 0.7519, Validation Accuracy: 75.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Training]: 100%|██████████| 13/13 [00:00<00:00, 213.83it/s, loss=0.0450]\n",
      "Epoch 5/10 [Validation]: 100%|██████████| 1250/1250 [00:01<00:00, 713.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] - Train Loss: 0.0301, Train Accuracy: 100.00%, Validation Loss: 0.6175, Validation Accuracy: 80.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Training]: 100%|██████████| 13/13 [00:00<00:00, 207.53it/s, loss=0.0399]\n",
      "Epoch 6/10 [Validation]: 100%|██████████| 1250/1250 [00:01<00:00, 713.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] - Train Loss: 0.0159, Train Accuracy: 100.00%, Validation Loss: 0.5036, Validation Accuracy: 84.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Training]: 100%|██████████| 13/13 [00:00<00:00, 91.44it/s, loss=0.0076]\n",
      "Epoch 7/10 [Validation]: 100%|██████████| 1250/1250 [00:01<00:00, 718.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] - Train Loss: 0.0091, Train Accuracy: 100.00%, Validation Loss: 0.4927, Validation Accuracy: 84.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Training]: 100%|██████████| 13/13 [00:00<00:00, 214.90it/s, loss=0.0100]\n",
      "Epoch 8/10 [Validation]: 100%|██████████| 1250/1250 [00:01<00:00, 719.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] - Train Loss: 0.0073, Train Accuracy: 100.00%, Validation Loss: 0.4889, Validation Accuracy: 84.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Training]: 100%|██████████| 13/13 [00:00<00:00, 196.63it/s, loss=0.0045]\n",
      "Epoch 9/10 [Validation]: 100%|██████████| 1250/1250 [00:01<00:00, 685.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] - Train Loss: 0.0062, Train Accuracy: 100.00%, Validation Loss: 0.4957, Validation Accuracy: 83.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Training]: 100%|██████████| 13/13 [00:00<00:00, 221.15it/s, loss=0.0072]\n",
      "Epoch 10/10 [Validation]: 100%|██████████| 1250/1250 [00:01<00:00, 709.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] - Train Loss: 0.0044, Train Accuracy: 100.00%, Validation Loss: 0.4782, Validation Accuracy: 84.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "supervised_train_loader = DataLoader(supervised_dataset, batch_size=8, shuffle=True,num_workers=4,persistent_workers=True)\n",
    "supervised_val_loader = DataLoader(test_dataset, batch_size=8, shuffle=False,num_workers=4,persistent_workers=True)\n",
    "optimizer=torch.optim.Adam(MNIST_model.parameters(),lr=0.001,weight_decay=0.001)\n",
    "\n",
    "train_convnet(MNIST_model,\n",
    "             supervised_train_loader,\n",
    "             supervised_val_loader,\n",
    "             criterion,optimizer,\n",
    "             learning_rate_scheduler,\n",
    "             num_epochs=10,\n",
    "             filename=f'mnist_model_{NUM_BLOCKS}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.16%\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(MNIST_model,supervised_val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
